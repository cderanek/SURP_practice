{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4aad30",
   "metadata": {},
   "source": [
    "# NEON API exploration\n",
    "\n",
    "In this file, I'll be exploring the NEON API using [this NEON API tutorial](https://www.neonscience.org/resources/learning-hub/tutorials/neon-api-01-introduction-requests) and NEON AOP HDF5 reflectance files using [this NEON AOP HDF5 tutorial](https://www.neonscience.org/resources/learning-hub/tutorials/neon-aop-hdf5-tile-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8389cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # necessary for NEON API\n",
    "import json\n",
    "\n",
    "import numpy as np # necessary for exploring h5 files\n",
    "import h5py\n",
    "import osgeo.gdal, osgeo.osr, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import namedtuple # for nicely organizing the many URLs and metadata\n",
    "from itertools import chain # flattening a list when iterating very nested json info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248d39b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To request data, need to provide NEON's URL\n",
    "SERVER = 'http://data.neonscience.org/api/v0/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66006762",
   "metadata": {},
   "source": [
    "Some of the important endpoints for NEON are:\n",
    "* _sites/_\n",
    "* _products/_\n",
    "* _data/_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62903cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sites of interest\n",
    "SITECODE_LIST = ['TEAK', 'SOAP', 'SJER']\n",
    "\n",
    "# Make requests, then turn request data into a Python JSON object so it's easier to interact with\n",
    "site_json_list = [requests.get(SERVER+'sites/'+SITECODE).json() \n",
    "                          for SITECODE in SITECODE_LIST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a71b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display json info TEAK site\n",
    "TEAK_json = site_json_list[0]\n",
    "## TEAK_json ## super long output -- uncomment if you want to see"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de28497b",
   "metadata": {},
   "source": [
    "That was a huge dict...let's explore smaller parts and try to avoid listing the many dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b473be1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data']) \n",
      "\n",
      "siteCode:\t<class 'str'>\n",
      "siteName:\t<class 'str'>\n",
      "siteDescription:\t<class 'str'>\n",
      "siteType:\t<class 'str'>\n",
      "siteLatitude:\t<class 'float'>\n",
      "siteLongitude:\t<class 'float'>\n",
      "stateCode:\t<class 'str'>\n",
      "stateName:\t<class 'str'>\n",
      "domainCode:\t<class 'str'>\n",
      "domainName:\t<class 'str'>\n",
      "deimsId:\t<class 'str'>\n",
      "releases:\t<class 'list'>\n",
      "dataProducts:\t<class 'list'> \n",
      "\n",
      "Exploring dataProducts\n",
      "dataProducts contains a bunch of dicts...\n",
      "<class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'>, <class 'dict'> \n",
      "\n",
      "What is in each of those dicts? They all have the same structure.\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases'])\n",
      "dict_keys(['dataProductCode', 'dataProductTitle', 'availableMonths', 'availableDataUrls', 'availableReleases']) \n",
      "\n",
      "What are the data product codes and titles?\n",
      "DP1.00001.001\t2D wind speed and direction\n",
      "DP1.00002.001\tSingle aspirated air temperature\n",
      "DP1.00003.001\tTriple aspirated air temperature\n",
      "DP1.00004.001\tBarometric pressure\n",
      "DP1.00005.001\tIR biological temperature\n",
      "DP1.00006.001\tPrecipitation\n",
      "DP1.00014.001\tShortwave radiation (direct and diffuse pyranometer)\n",
      "DP1.00023.001\tShortwave and longwave radiation (net radiometer)\n",
      "DP1.00024.001\tPhotosynthetically active radiation (PAR)\n",
      "DP1.00033.001\tPhenology images\n",
      "DP1.00040.001\tSoil heat flux plate\n",
      "DP1.00041.001\tSoil temperature\n",
      "DP1.00042.001\tSnow depth and understory phenology images\n",
      "DP1.00066.001\tPhotosynthetically active radiation (quantum line)\n",
      "DP1.00094.001\tSoil water content and water salinity\n",
      "DP1.00095.001\tSoil CO2 concentration\n",
      "DP1.00096.001\tSoil physical and chemical properties, Megapit\n",
      "DP1.00098.001\tRelative humidity\n",
      "DP1.10003.001\tBreeding landbird point counts\n",
      "DP1.10010.001\tCoarse downed wood log survey\n",
      "DP1.10017.001\tDigital hemispheric photos of plot vegetation\n",
      "DP1.10020.001\tGround beetle sequences DNA barcode\n",
      "DP1.10022.001\tGround beetles sampled from pitfall traps\n",
      "DP1.10023.001\tHerbaceous clip harvest\n",
      "DP1.10026.001\tPlant foliar traits\n",
      "DP1.10033.001\tLitterfall and fine woody debris production and chemistry\n",
      "DP1.10038.001\tMosquito sequences DNA barcode\n",
      "DP1.10041.001\tMosquito pathogen status\n",
      "DP1.10043.001\tMosquitoes sampled from CO2 traps\n",
      "DP1.10055.001\tPlant phenology observations\n",
      "DP1.10058.001\tPlant presence and percent cover\n",
      "DP1.10064.001\tRodent pathogen status, hantavirus\n",
      "DP1.10064.002\tRodent pathogen status, tick-borne\n",
      "DP1.10066.001\tRoot biomass and chemistry, Megapit\n",
      "DP1.10067.001\tRoot biomass and chemistry, periodic\n",
      "DP1.10072.001\tSmall mammal box trapping\n",
      "DP1.10076.001\tSmall mammal sequences DNA barcode\n",
      "DP1.10086.001\tSoil physical and chemical properties, periodic\n",
      "DP1.10093.001\tTicks sampled using drag cloths\n",
      "DP1.10098.001\tVegetation structure\n",
      "DP1.10104.001\tSoil microbe biomass\n",
      "DP1.10111.001\tSite management and event reporting\n",
      "DP1.30001.001\tLiDAR slant range waveform\n",
      "DP1.30003.001\tDiscrete return LiDAR point cloud\n",
      "DP1.30006.001\tSpectrometer orthorectified surface directional reflectance - flightline\n",
      "DP1.30008.001\tSpectrometer orthrorectified at-sensor radiance - flightline\n",
      "DP1.30010.001\tHigh-resolution orthorectified camera imagery\n",
      "DP2.30011.001\tAlbedo - spectrometer - flightline\n",
      "DP2.30012.001\tLAI - spectrometer - flightline\n",
      "DP2.30014.001\tfPAR - spectrometer - flightline\n",
      "DP2.30019.001\tCanopy water indices - flightline\n",
      "DP2.30026.001\tVegetation indices - spectrometer - flightline\n",
      "DP3.30006.001\tSpectrometer orthorectified surface directional reflectance - mosaic\n",
      "DP3.30010.001\tHigh-resolution orthorectified camera imagery mosaic\n",
      "DP3.30011.001\tAlbedo - spectrometer - mosaic\n",
      "DP3.30012.001\tLAI - spectrometer - mosaic\n",
      "DP3.30014.001\tfPAR - spectrometer - mosaic\n",
      "DP3.30015.001\tEcosystem structure\n",
      "DP3.30019.001\tCanopy water indices - mosaic\n",
      "DP3.30024.001\tElevation - LiDAR\n",
      "DP3.30025.001\tSlope and Aspect - LiDAR\n",
      "DP3.30026.001\tVegetation indices - spectrometer - mosaic\n",
      "DP4.00200.001\tBundled data products - eddy covariance \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(TEAK_json.keys(),'\\n') # original dict only has 1 key -- 'data'\n",
    "\n",
    "# look at info inside of 'data' key\n",
    "NEON_dataDict_info = [str(key)+':\\t'+str(type(TEAK_json['data'][key])) \n",
    "                          for key in TEAK_json['data'].keys()] \n",
    "print('\\n'.join(NEON_dataDict_info), '\\n')\n",
    "\n",
    "\n",
    "# data products looked most interesting because I want to use that list to query products of interest\n",
    "print('Exploring dataProducts')\n",
    "dataProduct_Info = [str(type(product)) \n",
    "                        for product in TEAK_json['data']['dataProducts']] \n",
    "print('dataProducts contains a bunch of dicts...')\n",
    "print(', '.join(dataProduct_Info), '\\n')\n",
    "\n",
    "\n",
    "print('What is in each of those dicts? They all have the same structure.')\n",
    "dataProducts_ListOfDicts = TEAK_json['data']['dataProducts']\n",
    "NEON_dataProducts_info = [str(subDict.keys())\n",
    "                              for subDict in dataProducts_ListOfDicts] \n",
    "print('\\n'.join(NEON_dataProducts_info), '\\n')\n",
    "\n",
    "\n",
    "print('What are the data product codes and titles?')\n",
    "NEON_dataProductCodes_info = [str(productDict['dataProductCode'])+'\\t'+str(productDict['dataProductTitle'])\n",
    "                                  for productDict in dataProducts_ListOfDicts] \n",
    "print('\\n'.join(NEON_dataProductCodes_info), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83b4d0",
   "metadata": {},
   "source": [
    "# Filtering URLs (for eventual download)\n",
    "\n",
    "Using this information about the data available for my 3 sites of interest, I want to download data that meet the following specifications for each site:\n",
    "* Data products:\n",
    "    * Vegetation structure (DP1.10098.001)\n",
    "    * Elevation - LiDAR (DP3.30024.001)\n",
    "    * Spectrometer orthorectified surface directional reflectance - mosaic (DP3.30006.001)\n",
    "* Most recent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b150a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRODUCT_METADATA(SITE='TEAK', PRODUCT_TITLE='Vegetation structure', PRODUCT_CODE='DP1.10098.001', DATE='2021-12', URL='https://data.neonscience.org/api/v0/data/DP1.10098.001/TEAK/2021-12'), PRODUCT_METADATA(SITE='TEAK', PRODUCT_TITLE='Spectrometer orthorectified surface directional reflectance - mosaic', PRODUCT_CODE='DP3.30006.001', DATE='2021-07', URL='https://data.neonscience.org/api/v0/data/DP3.30006.001/TEAK/2021-07'), PRODUCT_METADATA(SITE='TEAK', PRODUCT_TITLE='Elevation - LiDAR', PRODUCT_CODE='DP3.30024.001', DATE='2021-07', URL='https://data.neonscience.org/api/v0/data/DP3.30024.001/TEAK/2021-07'), PRODUCT_METADATA(SITE='SOAP', PRODUCT_TITLE='Vegetation structure', PRODUCT_CODE='DP1.10098.001', DATE='2022-01', URL='https://data.neonscience.org/api/v0/data/DP1.10098.001/SOAP/2022-01'), PRODUCT_METADATA(SITE='SOAP', PRODUCT_TITLE='Spectrometer orthorectified surface directional reflectance - mosaic', PRODUCT_CODE='DP3.30006.001', DATE='2021-07', URL='https://data.neonscience.org/api/v0/data/DP3.30006.001/SOAP/2021-07'), PRODUCT_METADATA(SITE='SOAP', PRODUCT_TITLE='Elevation - LiDAR', PRODUCT_CODE='DP3.30024.001', DATE='2021-07', URL='https://data.neonscience.org/api/v0/data/DP3.30024.001/SOAP/2021-07'), PRODUCT_METADATA(SITE='SJER', PRODUCT_TITLE='Vegetation structure', PRODUCT_CODE='DP1.10098.001', DATE='2022-02', URL='https://data.neonscience.org/api/v0/data/DP1.10098.001/SJER/2022-02'), PRODUCT_METADATA(SITE='SJER', PRODUCT_TITLE='Spectrometer orthorectified surface directional reflectance - mosaic', PRODUCT_CODE='DP3.30006.001', DATE='2021-03', URL='https://data.neonscience.org/api/v0/data/DP3.30006.001/SJER/2021-03'), PRODUCT_METADATA(SITE='SJER', PRODUCT_TITLE='Elevation - LiDAR', PRODUCT_CODE='DP3.30024.001', DATE='2021-03', URL='https://data.neonscience.org/api/v0/data/DP3.30024.001/SJER/2021-03')]\n"
     ]
    }
   ],
   "source": [
    "# Specifications\n",
    "SERVER = 'http://data.neonscience.org/api/v0/'\n",
    "SITES_LIST = ['TEAK', 'SOAP', 'SJER']\n",
    "DATAPRODUCTS_DICT = {'Vegetation structure': 'DP1.10098.001', \n",
    "                     'Elevation - LiDAR': 'DP3.30024.001', \n",
    "                     'Spectrometer orthorectified surface directional reflectance - mosaic': 'DP3.30006.001'}\n",
    "\n",
    "## Get a list of URLs for data to download ##\n",
    "\n",
    "# get json info for my sites of interest\n",
    "site_json_list = [requests.get(SERVER+'sites/'+site).json() \n",
    "                          for site in SITES_LIST]\n",
    "\n",
    "# for each site, extract only the relevant dataproducts\n",
    "dataprod_codes_list = list(DATAPRODUCTS_DICT.values())\n",
    "\n",
    "def getProductsAtSite(site_json, dataprod_codes_list):\n",
    "    return [site_dataProd_dict\n",
    "            for site_dataProd_dict in site_json['data']['dataProducts']\n",
    "            if site_dataProd_dict['dataProductCode'] in dataprod_codes_list\n",
    "           ]\n",
    "\n",
    "site_dataprod_dict = {site_json['data']['siteCode']:\n",
    "                      getProductsAtSite(site_json, dataprod_codes_list)\n",
    "                      for site_json in site_json_list}\n",
    "\n",
    "## get the URL and only relevant metadata for only the most recent available datasets\n",
    "# for each site, create a named tuple of tuples of the format below\n",
    "productTupleNames = namedtuple('PRODUCT_METADATA', ['SITE','PRODUCT_TITLE', 'PRODUCT_CODE', 'DATE', 'URL'])\n",
    "\n",
    "# for all products at all sites, get the metadata needed for our named productTuple\n",
    "productTupleMetadata = list(chain(*[\n",
    "    [(site,\n",
    "      productD['dataProductTitle'],\n",
    "      productD['dataProductCode'],\n",
    "      productD['availableMonths'][-1],\n",
    "      productD['availableDataUrls'][-1]\n",
    "     )\n",
    "     for productD in site_dataprod_dict[site]\n",
    "    ]\n",
    "    for site in site_dataprod_dict.keys()\n",
    "]))\n",
    "\n",
    "# the final named tuple with only our sites, products, and dates of interest\n",
    "productTupleL=[productTupleNames(*productInfo)\n",
    "               for productInfo in productTupleMetadata]\n",
    "\n",
    "print(productTupleL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c94925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEAK \t| Vegetation structure\n",
      "vst perplotperyear 2021-12 basic 20220711T220416Z csv\n",
      "variables 20220711T220416Z csv\n",
      "vst apparentindividual 2021-12 basic 20220711T220416Z csv\n",
      "readme 20220711T220416Z txt\n",
      "validation 20220711T220416Z csv\n",
      "EML 20211207-20211208 20220711T220416Z xml\n",
      "vst mappingandtagging basic 20220711T220416Z csv\n",
      "categoricalCodes 20220711T220416Z csv \n",
      "\n",
      "\n",
      "TEAK \t| Spectrometer orthorectified surface directional reflectance - mosaic\n",
      "pdf\n",
      "readme 20211007T212640Z txt\n",
      "reflectance h5 \n",
      "\n",
      "\n",
      "TEAK \t| Elevation - LiDAR\n",
      "\n",
      "classified point cloud prj\n",
      "readme 20211007T212640Z txt\n",
      "DSM tif\n",
      "classified point cloud dbf\n",
      "classified point cloud shx\n",
      "DTM tif\n",
      "classified point cloud kml\n",
      "processing pdf\n",
      "classified point cloud shp \n",
      "\n",
      "\n",
      "SOAP \t| Vegetation structure\n",
      "variables 20220801T222504Z csv\n",
      "vst mappingandtagging basic 20220801T222504Z csv\n",
      "categoricalCodes 20220801T222504Z csv\n",
      "vst perplotperyear 2022-01 basic 20220801T222504Z csv\n",
      "readme 20220801T222504Z txt\n",
      "EML 20220117-20220117 20220801T222504Z xml\n",
      "validation 20220801T222504Z csv \n",
      "\n",
      "\n",
      "SOAP \t| Spectrometer orthorectified surface directional reflectance - mosaic\n",
      "readme 20220131T195357Z txt\n",
      "pdf\n",
      "reflectance h5 \n",
      "\n",
      "\n",
      "SOAP \t| Elevation - LiDAR\n",
      "\n",
      "classified point cloud prj\n",
      "readme 20211007T212640Z txt\n",
      "DSM tif\n",
      "classified point cloud dbf\n",
      "classified point cloud shx\n",
      "DTM tif\n",
      "classified point cloud kml\n",
      "processing pdf\n",
      "classified point cloud shp \n",
      "\n",
      "\n",
      "SJER \t| Vegetation structure\n",
      "vst mappingandtagging basic 20220829T155208Z csv\n",
      "variables 20220829T155208Z csv\n",
      "EML 20220201-20220202 20220829T155208Z xml\n",
      "categoricalCodes 20220829T155208Z csv\n",
      "readme 20220829T155208Z txt\n",
      "vst perplotperyear 2022-02 basic 20220829T155208Z csv\n",
      "vst apparentindividual 2022-02 basic 20220829T155208Z csv\n",
      "validation 20220829T155208Z csv \n",
      "\n",
      "\n",
      "SJER \t| Spectrometer orthorectified surface directional reflectance - mosaic\n",
      "\n",
      "reflectance h5\n",
      "pdf\n",
      "readme 20220120T173946Z txt\n",
      "spectrometer processing pdf \n",
      "\n",
      "\n",
      "SJER \t| Elevation - LiDAR\n",
      "\n",
      "classified point cloud prj\n",
      "DSM tif\n",
      "classified point cloud dbf\n",
      "readme 20220302T205717Z txt\n",
      "classified point cloud shx\n",
      "DTM tif\n",
      "classified point cloud kml\n",
      "processing pdf\n",
      "classified point cloud shp \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# exploring the files to download from each URL\n",
    "for product_metadata in productTupleL:\n",
    "    # make request with saved url\n",
    "    data_request = requests.get(product_metadata.URL)\n",
    "    data_json = data_request.json()\n",
    "    \n",
    "    # print info on the files we can access for this particular site and product\n",
    "    print(product_metadata.SITE, '\\t|', product_metadata.PRODUCT_TITLE)\n",
    "    print('\\n'.join(set([' '.join(fileD['name'].replace('.','_').split('_')[6:]) # the first 6 info slots are redundant \n",
    "                     for fileD in data_json['data']['files']]) # for clarity, I used set to remove duplicate printouts -- but there are LOTS of h5 files\n",
    "                   ),\n",
    "         '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22990155",
   "metadata": {},
   "source": [
    "# Detour: Downloading only 1 h5 file for initial exploration\n",
    "\n",
    "In my original workflow planning, I didn't really put together that there would be SO MANY files associated with each plot's DSM, DTM, and reflectance data, because the data are tiled. So, I'm taking a quick detour to explore reflectance data from a single tile and then I'll learn to put the tiles back into the original mosaic so I can proceed with my workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bcf30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "77e85a35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564adfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SURP",
   "language": "python",
   "name": "surp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
